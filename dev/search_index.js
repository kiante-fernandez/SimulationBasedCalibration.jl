var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Module","page":"API","title":"Module","text":"","category":"section"},{"location":"api/#SimulationBasedCalibration","page":"API","title":"SimulationBasedCalibration","text":"SimulationBasedCalibration\n\nSee documentation at:  https://kiante-fernandez.github.io/SimulationBasedCalibration.jl/dev/\n\n\n\n\n\n","category":"module"},{"location":"api/#Core-Types","page":"API","title":"Core Types","text":"","category":"section"},{"location":"api/#SimulationBasedCalibration.AbstractSBCBackend","page":"API","title":"SimulationBasedCalibration.AbstractSBCBackend","text":"AbstractSBCBackend\n\nAbstract type for SBC backends (model fitting implementations)\n\n\n\n\n\n","category":"type"},{"location":"api/#SimulationBasedCalibration.AbstractSBCGenerator","page":"API","title":"SimulationBasedCalibration.AbstractSBCGenerator","text":"AbstractSBCGenerator\n\nAbstract type for SBC generators (data generation mechanisms)\n\n\n\n\n\n","category":"type"},{"location":"api/#SimulationBasedCalibration.SBCDatasets","page":"API","title":"SimulationBasedCalibration.SBCDatasets","text":"SBCDatasets\n\nStructure to hold generated datasets and corresponding parameter values.\n\nFields\n\nvariables: Array of dictionaries with true parameter values\ngenerated: Array of generated datasets\n\n\n\n\n\n","category":"type"},{"location":"api/#SimulationBasedCalibration.SBCGeneratorFunction","page":"API","title":"SimulationBasedCalibration.SBCGeneratorFunction","text":"SBCGeneratorFunction <: AbstractSBCGenerator\n\nA generator that uses a function to create datasets.\n\nFields\n\nfunc: Function that generates a single dataset\nkwargs: Keyword arguments to pass to the function\n\n\n\n\n\n","category":"type"},{"location":"api/#SimulationBasedCalibration.SBCGeneratorFunction-Tuple{Any}","page":"API","title":"SimulationBasedCalibration.SBCGeneratorFunction","text":"SBCGeneratorFunction(func; kwargs...)\n\nCreate a generator from a function with keyword arguments.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.SBCResults","page":"API","title":"SimulationBasedCalibration.SBCResults","text":"SBCResults\n\nStructure to hold SBC results.\n\nFields\n\nstats: DataFrame with SBC statistics\nfits: Vector of fit objects\nerrors: Vector of error objects\n\n\n\n\n\n","category":"type"},{"location":"api/#SimulationBasedCalibration.TuringBackend","page":"API","title":"SimulationBasedCalibration.TuringBackend","text":"TuringBackend <: AbstractSBCBackend\n\nBackend for Turing.jl models.\n\nFields\n\nmodel_func: Function that takes data and returns a Turing model\nsampler: MCMC sampler to use\nn_chains: Number of chains to run\noptions: Additional options to pass to the Turing sampler\n\n\n\n\n\n","category":"type"},{"location":"api/#SimulationBasedCalibration.TuringBackend-Tuple{Function}","page":"API","title":"SimulationBasedCalibration.TuringBackend","text":"TuringBackend(model_func::Function; \n             sampler=Turing.NUTS(0.65),\n             n_chains=4,\n             kwargs...)\n\nCreate a Turing backend with the given options.\n\n\n\n\n\n","category":"method"},{"location":"api/#Core-Functions","page":"API","title":"Core Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The following are organized by category to avoid duplicates:","category":"page"},{"location":"api/#Generator-Functions","page":"API","title":"Generator Functions","text":"","category":"section"},{"location":"api/#SimulationBasedCalibration.generate_datasets-Tuple{SBCGeneratorFunction, Int64}","page":"API","title":"SimulationBasedCalibration.generate_datasets","text":"generate_datasets(generator::SBCGeneratorFunction, n_sims::Int)\n\nGenerate n_sims datasets using the given generator.\n\n\n\n\n\n","category":"method"},{"location":"api/#Backend-Functions","page":"API","title":"Backend Functions","text":"","category":"section"},{"location":"api/#SimulationBasedCalibration.diagnostics-Tuple{Any}","page":"API","title":"SimulationBasedCalibration.diagnostics","text":"diagnostics(fit_result)\n\nExtract diagnostics from a fit result.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.diagnostics-Tuple{MCMCChains.Chains}","page":"API","title":"SimulationBasedCalibration.diagnostics","text":"diagnostics(chain::MCMCChains.Chains)\n\nExtract diagnostics from a Turing MCMC chain.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.draws_matrix-Tuple{Any}","page":"API","title":"SimulationBasedCalibration.draws_matrix","text":"draws_matrix(fit_result)\n\nConvert a fit result to a draws matrix format.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.draws_matrix-Tuple{MCMCChains.Chains}","page":"API","title":"SimulationBasedCalibration.draws_matrix","text":"draws_matrix(chain::Chains)\n\nConvert Turing MCMCChains to a DataFrame of posterior draws.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.fit-Tuple{AbstractSBCBackend, Any}","page":"API","title":"SimulationBasedCalibration.fit","text":"fit(backend::AbstractSBCBackend, generated)\n\nFit a model using the given backend to the generated data.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.fit-Tuple{TuringBackend, Any}","page":"API","title":"SimulationBasedCalibration.fit","text":"fit(backend::TuringBackend, data)\n\nFit the Turing model to the given data.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.iid_draws-Tuple{AbstractSBCBackend}","page":"API","title":"SimulationBasedCalibration.iid_draws","text":"iid_draws(backend::AbstractSBCBackend)\n\nReturn true if the backend produces independent and identically distributed draws.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.iid_draws-Tuple{TuringBackend}","page":"API","title":"SimulationBasedCalibration.iid_draws","text":"iid_draws(backend::TuringBackend)\n\nCheck if the backend produces iid draws.\n\n\n\n\n\n","category":"method"},{"location":"api/#Computation-Functions","page":"API","title":"Computation Functions","text":"","category":"section"},{"location":"api/#SimulationBasedCalibration.calculate_ranks-Tuple{Any, Any}","page":"API","title":"SimulationBasedCalibration.calculate_ranks","text":"calculate_ranks(variables, draws)\n\nCalculate the rank of each true parameter value within posterior draws.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.compute_sbc-Tuple{SBCDatasets, AbstractSBCBackend}","page":"API","title":"SimulationBasedCalibration.compute_sbc","text":"compute_sbc(datasets::SBCDatasets, \n            backend::AbstractSBCBackend;\n            keep_fits::Bool=true,\n            thin_ranks::Int=default_thin_ranks(backend),\n            ensure_num_ranks_divisor::Int=2)\n\nCompute SBC results for the given datasets using the specified backend.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.compute_statistics-NTuple{4, Any}","page":"API","title":"SimulationBasedCalibration.compute_statistics","text":"compute_statistics(fit_result, variables, thin_ranks, ensure_num_ranks_divisor)\n\nCompute SBC statistics for a single fit.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.default_thin_ranks-Tuple{AbstractSBCBackend}","page":"API","title":"SimulationBasedCalibration.default_thin_ranks","text":"default_thin_ranks(backend::AbstractSBCBackend)\n\nReturn the default thinning factor for rank calculation.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.thin_draws-Tuple{Any, Any}","page":"API","title":"SimulationBasedCalibration.thin_draws","text":"thin_draws(draws, thin)\n\nApply thinning to posterior draws.\n\n\n\n\n\n","category":"method"},{"location":"api/#Visualization-Functions","page":"API","title":"Visualization Functions","text":"","category":"section"},{"location":"api/#SimulationBasedCalibration.plot_ecdf-Tuple{SBCResults}","page":"API","title":"SimulationBasedCalibration.plot_ecdf","text":"plot_ecdf(results::SBCResults; \n          variables=nothing,\n          prob=0.95)\n\nPlot empirical CDF plots for SBC results.\n\n\n\n\n\n","category":"method"},{"location":"api/#SimulationBasedCalibration.plot_rank_hist-Tuple{SBCResults}","page":"API","title":"SimulationBasedCalibration.plot_rank_hist","text":"plot_rank_hist(results::SBCResults; \n               variables=nothing, \n               bins=nothing,\n               prob=0.95)\n\nPlot rank histograms for SBC results.\n\n\n\n\n\n","category":"method"},{"location":"api/#Other-Functions","page":"API","title":"Other Functions","text":"","category":"section"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#Basic-Usage","page":"Examples","title":"Basic Usage","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Here's a basic example of using SimulationBasedCalibration.jl with Turing.jl:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using SimulationBasedCalibration\nusing Turing, Random, Distributions\n\n# Set random seed for reproducibility\nRandom.seed!(123)\n\n# Define the correct model\n@model function normal_model(data)\n    # Priors\n    μ ~ Normal(0, 5)\n    σ ~ truncated(Normal(0, 3), 0, Inf)\n    \n    # Likelihood - correctly parameterized\n    data ~ MvNormal(fill(μ, length(data)), σ^2 * I)\nend\n\n# Define a generator function matching our model\nfunction normal_generator(; n_obs=20)\n    μ = rand(Normal(0, 5))\n    σ = rand(truncated(Normal(0, 3), 0, Inf))\n    data = rand(Normal(μ, σ), n_obs)\n    \n    return Dict(\n        :variables => Dict(:μ => μ, :σ => σ),\n        :generated => data\n    )\nend\n\n# Create generator and backend\ngenerator = SBCGeneratorFunction(normal_generator, n_obs=200)\nbackend = TuringBackend(normal_model, n_samples=1000, n_chains=3)\n\n# Generate datasets\ndatasets = generate_datasets(generator, 100)\n\n# Run SBC\nresults = compute_sbc(datasets, backend)\n\n# Visualize the results\np1 = plot_rank_hist(results)\np2 = plot_ecdf(results)","category":"page"},{"location":"examples/#Detecting-Model-Misspecification","page":"Examples","title":"Detecting Model Misspecification","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"You can also use SBC to detect misspecified models:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Define an incorrect model\n@model function normal_model_bad(data)\n    # Priors \n    μ ~ Normal(0, 5)\n    σ ~ truncated(Normal(0, 3), 0, Inf)\n    \n    # Likelihood - incorrectly parameterized (using precision instead of sd)\n    data ~ MvNormal(fill(μ, length(data)), (1/σ)^2 * I)\nend\n\n# Create a backend for the bad model\nbackend_bad = TuringBackend(normal_model_bad, n_samples=1000, n_chains=2)\n\n# Run SBC with the bad model\nresults_bad = compute_sbc(datasets, backend_bad)\n\n# Compare results\nplot_rank_hist(results_bad)","category":"page"},{"location":"#SimulationBasedCalibration.jl","page":"Home","title":"SimulationBasedCalibration.jl","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides tools to validate Bayesian models and inference algorithms via simulation-based calibration (SBC). It integrates with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Turing.jl: Probabilistic programming for Bayesian inference","category":"page"},{"location":"#Background","page":"Home","title":"Background","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Simulation-based calibration (SBC) is a method for validating Bayesian computational methods by checking the self-consistency of the posterior distribution. SBC tests whether your model and inference algorithm can recover known parameter values by repeatedly:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Sampling parameters from the prior\nSimulating data under those parameters\nFitting the model to the simulated data\nChecking if the true parameter values are distributed as expected in the posteriors","category":"page"},{"location":"","page":"Home","title":"Home","text":"For correctly calibrated models and inference algorithms, the rank of the true parameter value within posterior samples should follow a uniform distribution:","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can install SimulationBasedCalibration.jl by running:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"SimulationBasedCalibration\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"For the development version:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/kiante-fernandez/SimulationBasedCalibration.jl\")","category":"page"},{"location":"#Quick-Example","page":"Home","title":"Quick Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This example demonstrates how to use SBC to validate a simple Bayesian model:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using SimulationBasedCalibration\nusing Turing, Random, Distributions, Plots\n\n# Set random seed for reproducibility\nRandom.seed!(2025)\n\n# Define a Turing.jl model (normal mean and standard deviation)\n@model function normal_model(data)\n    μ ~ Normal(0, 5)\n    σ ~ truncated(Normal(0, 3), 0, Inf)\n    data ~ MvNormal(fill(μ, length(data)), σ^2 * I)\nend\n\n# Define a generator function matching our model\nfunction normal_generator(; n_obs=20)\n    # Sample from priors\n    μ = rand(Normal(0, 5))\n    σ = rand(truncated(Normal(0, 3), 0, Inf))\n    \n    # Generate data\n    data = rand(Normal(μ, σ), n_obs)\n    \n    return Dict(\n        :variables => Dict(:μ => μ, :σ => σ),\n        :generated => data\n    )\nend\n\n# Create generator and backend\ngenerator = SBCGeneratorFunction(normal_generator, n_obs=20)\nbackend = TuringBackend(normal_model, n_samples=1000, n_chains=2)\n\n# Generate datasets and run SBC\ndatasets = generate_datasets(generator, 50)\nresults = compute_sbc(datasets, backend)\n\n# Visualize the results\nplot_rank_hist(results)\nplot_ecdf(results)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The rank histogram should appear uniform if the model is correctly specified and the inference algorithm is working properly.","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Talts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gelman, A. (2018). Validating Bayesian Inference Algorithms with Simulation-Based Calibration. arXiv Preprint arXiv:1804.06788.\nModrák, M., Moon, A. H., Kim, S., Bürkner, P., Huurre, N., Faltejsková, K., ... & Vehtari, A. (2023). Simulation-based calibration checking for Bayesian computation: The choice of test quantities shapes sensitivity. Bayesian Analysis, advance publication, DOI: 10.1214/23-BA1404.\nSäilynoja, T., Bürkner, P., & Vehtari, A. (2021). Graphical Test for Discrete Uniformity and its Applications in Goodness of Fit Evaluation and Multiple Sample Comparison. arXiv Preprint arXiv:2103.10522.\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., ... & Modrák, M. (2020). Bayesian Workflow. arXiv Preprint arXiv:2011.01808.\nSchad, D. J., Betancourt, M., & Vasishth, S. (2021). Toward a principled Bayesian workflow in cognitive science. Psychological Methods, 26(1), 103-126.","category":"page"}]
}
